{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading in the data and then filtering out SNPs which do not meet p value significance before joining the data together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(75089, 26)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "\n",
    "# exp: Exposure\n",
    "# out: Outcome\n",
    "# ea: Exposure allele\n",
    "# oa: Other allele\n",
    "\n",
    "exp_header_dict = {\n",
    "  'rsID':'rsid',\n",
    "  'CHROM':'chr_exp',\n",
    "  'ALT':'ea_exp',\n",
    "  'REF':'oa_exp',\n",
    "  'POOLED_ALT_AF':'maf_exp',\n",
    "  'EFFECT_SIZE':'beta_exp',\n",
    "  'SE':'se_exp',\n",
    "  'pvalue':'pval_exp'\n",
    "}\n",
    "\n",
    "out_header_dict = {\n",
    "  'markername':'rsid',\n",
    "  'chr':'chr_out',\n",
    "  'bp_hg19':'pos_out',\n",
    "  'effect_allele':'ea_out',\n",
    "  'noneffect_allele':'oa_out',\n",
    "  'effect_allele_freq':'ea_freq',\n",
    "  'beta':'beta_out',\n",
    "  'se_dgc':'se_out',\n",
    "  'p_dgc':'pval_out'}\n",
    "\n",
    "pthresh = 5e-8\n",
    "\n",
    "# Renaming columns and filtering data to only include observations which fulfill significance threshold\n",
    "dexp = (pl.scan_csv(\"dataset/ldlc_gwas.txt\",separator=\"\\t\")\n",
    "        .rename(exp_header_dict)\n",
    "        .filter((pl.col('pval_exp') < pthresh)))\n",
    "dout = (pl.scan_csv(\"dataset/mi_gwas.tsv\",separator=\"\\t\")\n",
    "        .rename(out_header_dict))\n",
    "\n",
    "combined = (dexp.join(dout, on='rsid')\n",
    "            # Convert all data to lowercase\n",
    "            .with_columns(pl.col('ea_exp').str.to_lowercase())\n",
    "            .with_columns(pl.col('oa_exp').str.to_lowercase())\n",
    "            .with_columns(pl.col('ea_out').str.to_lowercase())\n",
    "            .with_columns(pl.col('oa_out').str.to_lowercase())\n",
    "            .collect())\n",
    "\n",
    "print(combined.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harmonizing the data.\n",
    "\n",
    "Gathering all SNPs using fowards strand with matching effect and alternate alleles between exposure and outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwards_same = combined.filter(((pl.col('ea_exp') == pl.col('ea_out')) & (pl.col('oa_exp') == pl.col('oa_out'))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering all SNPs using forwards strand with flipped effect and alternate alleles between exposure and outcome. The effect is then multiplied by -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "forwards_flipped = (\n",
    "  combined.filter(((pl.col('ea_exp') == pl.col('oa_out')) & (pl.col('oa_exp') == pl.col('ea_out'))))\n",
    "  # Flip the signs of the outcome effects\n",
    "  .with_columns(\n",
    "    pl.col('beta_out').mul(-1),\n",
    "    pl.col('ea_freq').mul(-1).add(1)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Flipping the outcome alleles of the remaining SNPs since the remaining valid SNPs must use the reverse strand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find cases where alleles don't match\n",
    "reverse = (combined.filter(~(((pl.col('ea_exp') == pl.col('ea_out')) & (pl.col('oa_exp') == pl.col('oa_out'))) | \n",
    "                            (((pl.col('ea_exp') == pl.col('oa_out')) & (pl.col('oa_exp') == pl.col('ea_out'))))))\n",
    "            # Flipping the alleles\n",
    "            .with_columns(pl.col('ea_out').str.replace('a', 't'))\n",
    "            .with_columns(pl.col('ea_out').str.replace('t', 'a'))\n",
    "            .with_columns(pl.col('ea_out').str.replace('g', 'c'))\n",
    "            .with_columns(pl.col('ea_out').str.replace('c', 'g'))\n",
    "            .with_columns(pl.col('oa_out').str.replace('a', 't'))\n",
    "            .with_columns(pl.col('oa_out').str.replace('t', 'a'))\n",
    "            .with_columns(pl.col('oa_out').str.replace('g', 'c'))\n",
    "            .with_columns(pl.col('oa_out').str.replace('c', 'g'))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering SNPs from reverse strand which use the same alleles for exposure and outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_same = (\n",
    "  reverse.filter(((pl.col('ea_exp') == pl.col('ea_out')) & (pl.col('oa_exp') == pl.col('oa_out'))))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gathering SNPs from reverse strand which flipped the effect and alternate alleles. We then multiply the effect by -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_flipped = (\n",
    "  # Find all reversed cases\n",
    "  reverse.filter(((pl.col('ea_exp') == pl.col('oa_out')) & (pl.col('oa_exp') == pl.col('ea_out'))))\n",
    "  # Flip the signs of the outcome effects\n",
    "  .with_columns(\n",
    "    pl.col('beta_out').mul(-1),\n",
    "    pl.col('ea_freq').mul(-1).add(1)\n",
    "  )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining all the different cases into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8679, 26)\n",
      "(66342, 26)\n",
      "(1, 26)\n",
      "(6, 26)\n"
     ]
    }
   ],
   "source": [
    "print(forwards_same.shape)\n",
    "print(forwards_flipped.shape)\n",
    "print(reverse_same.shape)\n",
    "print(reverse_flipped.shape)\n",
    "\n",
    "# Combining all SNPs\n",
    "total = pl.concat([forwards_same, forwards_flipped, reverse_same, reverse_flipped])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discarding all palindromic SNPs since we are unable to determine whether the effect and outcome alleles are matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = total.filter(\n",
    "  ~(((pl.col('ea_exp') == 'a') & (pl.col('oa_exp') == 't')) |\n",
    "  ((pl.col('ea_exp') == 't') & (pl.col('oa_exp') == 'a')) |\n",
    "  ((pl.col('ea_exp') == 'g') & (pl.col('oa_exp') == 'c')) |\n",
    "  ((pl.col('ea_exp') == 'c') & (pl.col('oa_exp') == 'g')))\n",
    ")\n",
    "\n",
    "# maf_threshold = 0.6\n",
    "\n",
    "# palindromic = total.filter(((pl.col('ea_exp') == 'a') & (pl.col('oa_exp') == 't')) |\n",
    "#   ((pl.col('ea_exp') == 't') & (pl.col('oa_exp') == 'a')) |\n",
    "#   ((pl.col('ea_exp') == 'g') & (pl.col('oa_exp') == 'c')) |\n",
    "#   ((pl.col('ea_exp') == 'c') & (pl.col('oa_exp') == 'g')))\n",
    "\n",
    "# # If ea_freq is greater than threshold then we keep the SNP\n",
    "# # If ea_freq is less than 1-threshold, we keep SNP after negating the effect\n",
    "\n",
    "# print(palindromic.select(['ea_exp', 'oa_exp', 'ea_out', 'oa_out']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternatively, we can use the provided harmonize function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63712, 26)\n"
     ]
    }
   ],
   "source": [
    "from MR.harmonize import harmonize\n",
    "\n",
    "total = harmonize(combined)\n",
    "print(total.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruning the data based on Linkage Disequilibirum (LD)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MR.ld import ld_clump\n",
    "\n",
    "pruned_rsids = ld_clump(total['rsid'], total['pval_exp'])\n",
    "\n",
    "processed_data = (total.join(pruned_rsids, on='rsid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the causal effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IVW\n",
      "Effect: 0.5666555763511523\n",
      "se: 0.024475735763108256\n",
      "\n",
      "Wald ratio\n",
      "Effect: 0.5137645701874517\n",
      "se: 0.8410924885983558\n",
      "\n",
      "Simple Median\n",
      "Effect: 0.5909643015831363\n",
      "se: 0.051917455024275916\n",
      "\n",
      "Weighted Median\n",
      "Effect: 2.3022507995814996\n",
      "se: 0.13910938310717436\n",
      "\n",
      "Penalised Weighted Median\n",
      "Effect: 2.9361578831731068\n",
      "se: 0.2842617327917785\n",
      "\n",
      "Egger Regression\n",
      "Effect: 0.6500241298528222\n",
      "se: 0.04363211523625275\n",
      "\n",
      "Maximum Likelihood\n",
      "Effect: 0.5754979408718213\n",
      "se: 0.0003119327790360706\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from MR.calculate_effect import calculate_effect, methods\n",
    "\n",
    "# print(methods)\n",
    "\n",
    "import polars as pl\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "from statistics import stdev\n",
    "from scipy.stats import chi2\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "methods = [\n",
    "    'inverse_variance_weighted', \n",
    "    'wald_ratio', \n",
    "    'maximum_likelihood', \n",
    "    'simple_median', \n",
    "    'weighted_median', \n",
    "    'penalised_weighted_median',\n",
    "    'weighted_mode',\n",
    "    'egger_regression',\n",
    "    'presso'\n",
    "]\n",
    "\n",
    "\n",
    "def calculate_effect(data: pl.DataFrame, method: str):\n",
    "    \"\"\"\n",
    "    Calculates causal effect using the specified method.\n",
    "    List of methods can be accessed through the methods array.\n",
    "    \"\"\"\n",
    "    if method == 'inverse_variance_weighted':\n",
    "        return mr_inverse_variance_weighted(data['beta_exp'], data['beta_out'], data['se_out'])\n",
    "\n",
    "    elif method == 'wald_ratio':\n",
    "        return mr_wald_ratio(data['beta_exp'], data['beta_out'], data['se_out'])\n",
    "\n",
    "    elif method == 'maximum_likelihood':\n",
    "        return mr_maximum_likelihood(data['beta_exp'], data['beta_out'], data['se_exp'], data['se_out'])\n",
    "\n",
    "    elif method == 'simple_median':\n",
    "        return mr_simple_median(data['beta_exp'], data['beta_out'], data['se_exp'], data['se_out'])\n",
    "\n",
    "    elif method == 'weighted_median':\n",
    "        return mr_weighted_median(data['beta_exp'], data['beta_out'], data['se_exp'], data['se_out'])\n",
    "\n",
    "    elif method == 'penalised_weighted_median':\n",
    "        return mr_penalised_weighted_median(data['beta_exp'], data['beta_out'], data['se_exp'], data['se_out'])\n",
    "    \n",
    "    elif method == 'egger_regression':\n",
    "        return mr_egger_regression(data['beta_exp'], data['beta_out'], data['se_exp'], data['se_out'])\n",
    "\n",
    "\n",
    "def mr_inverse_variance_weighted(beta_exp, beta_out, se_out):\n",
    "    effect = (beta_exp * beta_out * se_out** -2).sum()/(beta_exp ** 2 * se_out ** -2).sum()\n",
    "    se = ((beta_exp ** 2 * se_out ** -2).sum()) ** -0.5\n",
    "\n",
    "    return {\n",
    "        'effect': effect, 'se': se\n",
    "    }\n",
    "\n",
    "\n",
    "def mr_wald_ratio(beta_exp, beta_out, se_out):\n",
    "    effect = (beta_out/beta_exp).mean()\n",
    "    se = (se_out/abs(beta_exp)).mean()\n",
    "\n",
    "    return {\n",
    "        'effect': effect, 'se': se\n",
    "    }\n",
    "\n",
    "\n",
    "def mr_maximum_likelihood(beta_exp, beta_out, se_exp, se_out):\n",
    "    n = len(beta_exp)\n",
    "\n",
    "    def log_likelihood(param):\n",
    "        return 1/2 * ((beta_exp - param[0:n])**2/se_exp**2).sum() + 1/2 * ((beta_out - param[n] * param[0:n])**2 / se_out**2).sum()\n",
    "\n",
    "    initial = np.append((beta_exp.to_numpy()), (beta_exp*beta_out /\n",
    "                                                se_out**2).sum()/(beta_exp**2/se_out**2).sum())\n",
    "\n",
    "    res = minimize(log_likelihood, initial)\n",
    "    effect = res.x[n]\n",
    "    se = res.hess_inv[n, n] ** 1/2\n",
    "\n",
    "    return {\n",
    "        'effect': effect, 'se': se\n",
    "    }\n",
    "\n",
    "\n",
    "def weighted_median(b_iv, weights):\n",
    "    beta_IV_sorted = np.sort(b_iv)\n",
    "    weights_sorted = np.sort(weights)\n",
    "    weights_sum = np.cumsum(weights_sorted) - 1/2 * weights_sorted\n",
    "    weights_sum = weights_sum/np.sum(weights_sorted)\n",
    "    below = np.max(np.where(weights_sum < 1/2))\n",
    "    return beta_IV_sorted[below-1] + (beta_IV_sorted[below] - beta_IV_sorted[below-1]) * (\n",
    "        1/2-weights_sum[below-1])/(weights_sum[below]-weights_sum[below-1])\n",
    "\n",
    "\n",
    "def weighted_median_se(beta_exp, beta_out, se_exp, se_out, weights, nboot=1000):\n",
    "    med = []\n",
    "    for i in range(0, nboot):\n",
    "        beta_exp_boot = np.random.normal(\n",
    "            loc=beta_exp, scale=se_exp, size=len(beta_exp))\n",
    "        beta_out_boot = np.random.normal(\n",
    "            loc=beta_out, scale=se_out, size=len(beta_out))\n",
    "        betaIV_boot = beta_out_boot/beta_exp_boot\n",
    "        med.append(weighted_median(betaIV_boot, weights))\n",
    "\n",
    "    return stdev(med)\n",
    "\n",
    "\n",
    "def mr_simple_median(beta_exp, beta_out, se_exp, se_out):\n",
    "    n = len(beta_exp)\n",
    "    b_iv = beta_out/beta_exp\n",
    "    effect = weighted_median(b_iv, np.repeat(1/n, n))\n",
    "    se = weighted_median_se(beta_exp, beta_out, se_exp,\n",
    "                            se_out, np.repeat(1/n, n))\n",
    "\n",
    "    return {\n",
    "        'effect': effect, 'se': se\n",
    "    }\n",
    "\n",
    "\n",
    "def mr_weighted_median(beta_exp, beta_out, se_exp, se_out):\n",
    "    b_iv = beta_out/beta_exp\n",
    "    VBj = se_out**2/beta_exp**2 + \\\n",
    "        beta_out**2 * se_exp**2/beta_exp**4\n",
    "    effect = weighted_median(b_iv, 1/VBj)\n",
    "    se = weighted_median_se(beta_exp, beta_out, se_exp, se_out, 1/VBj)\n",
    "\n",
    "    return {\n",
    "        'effect': effect, 'se': se\n",
    "    }\n",
    "\n",
    "\n",
    "def mr_penalised_weighted_median(beta_exp, beta_out, se_exp, se_out):\n",
    "    beta_iv = beta_out/beta_exp\n",
    "    beta_ivw = (beta_out*beta_exp*se_out**(-2)).sum()/(beta_exp**2*se_out**(-2)).sum()\n",
    "    VBj = se_out**2/beta_exp**2 + \\\n",
    "        beta_out**2 * se_exp**2/beta_exp**4\n",
    "    weights = 1/VBj\n",
    "    bwm = mr_weighted_median(beta_exp, beta_out, se_exp, se_out)\n",
    "    penalty = chi2.cdf(weights*beta_iv-bwm['effect']**2, df=1)\n",
    "    penalty_weights = penalty*weights\n",
    "    effect = weighted_median(beta_iv, penalty_weights)\n",
    "    se = weighted_median_se(beta_exp, beta_out, se_exp, se_out, penalty_weights)\n",
    "\n",
    "    return {\n",
    "        'effect': effect, 'se': se\n",
    "    }\n",
    "\n",
    "# def mr_simple_mode(beta_exp, beta_out, se_exp, se_out):\n",
    "\n",
    "def mr_egger_regression(beta_exp, beta_out, se_exp, se_out):\n",
    "    \n",
    "    def sign0(x):\n",
    "        x[x==0] = -1\n",
    "        return np.sign(x)\n",
    "    \n",
    "    # to_flip = sign0(beta_exp) == -1\n",
    "    beta_out = (beta_out * sign0(beta_exp)).to_numpy().reshape((-1,1))\n",
    "    beta_exp = abs(beta_exp).to_numpy().reshape((-1,1))\n",
    "    model = LinearRegression().fit(beta_exp, \n",
    "                                   beta_out,\n",
    "                                   sample_weight=se_out**(-2))\n",
    "    \n",
    "    # Code for the following is drawn from\n",
    "    # https://gist.github.com/grisaitis/cf481034bb413a14d3ea851dab201d31\n",
    "    def get_se():\n",
    "        N = len(beta_exp)\n",
    "        p = 2\n",
    "        X_with_intercept = np.empty(shape=(N, p), dtype=float)\n",
    "        X_with_intercept[:, 0] = 1\n",
    "        X_with_intercept[:, 1:p] = beta_exp\n",
    "        predictions = model.predict(beta_exp)\n",
    "        residuals = beta_out - predictions\n",
    "        residual_sum_of_squares = residuals.T @ residuals\n",
    "        sigma_squared_hat = residual_sum_of_squares[0, 0] / (N - p)\n",
    "        var_beta_hat = np.linalg.inv(X_with_intercept.T @ X_with_intercept) * sigma_squared_hat\n",
    "        return [var_beta_hat[p_, p_] ** 0.5 for p_ in range(p)]\n",
    "    \n",
    "    effect = model.coef_[0][0]\n",
    "\n",
    "    # se = get_se()[1] / min(1, model.sigma)\n",
    "    se = get_se()[1]\n",
    "\n",
    "    return {\n",
    "        'effect': effect, 'se': se\n",
    "    }\n",
    "    \n",
    "\n",
    "print('IVW')\n",
    "result = calculate_effect(processed_data, 'inverse_variance_weighted')\n",
    "print(f'Effect: {result[\"effect\"]}')\n",
    "print(f'se: {result[\"se\"]}\\n')\n",
    "\n",
    "print('Wald ratio')\n",
    "result = calculate_effect(processed_data, 'wald_ratio')\n",
    "print(f'Effect: {result[\"effect\"]}')\n",
    "print(f'se: {result[\"se\"]}\\n')\n",
    "\n",
    "print('Simple Median')\n",
    "result = calculate_effect(processed_data, 'simple_median')\n",
    "print(f'Effect: {result[\"effect\"]}')\n",
    "print(f'se: {result[\"se\"]}\\n')\n",
    "\n",
    "print('Weighted Median')\n",
    "result = calculate_effect(processed_data, 'weighted_median')\n",
    "print(f'Effect: {result[\"effect\"]}')\n",
    "print(f'se: {result[\"se\"]}\\n')\n",
    "\n",
    "print('Penalised Weighted Median')\n",
    "result = calculate_effect(processed_data, 'penalised_weighted_median')\n",
    "print(f'Effect: {result[\"effect\"]}')\n",
    "print(f'se: {result[\"se\"]}\\n')\n",
    "\n",
    "print('Egger Regression')\n",
    "result = calculate_effect(processed_data, 'egger_regression')\n",
    "print(f'Effect: {result[\"effect\"]}')\n",
    "print(f'se: {result[\"se\"]}\\n')\n",
    "\n",
    "print('Maximum Likelihood')\n",
    "result = calculate_effect(processed_data, 'maximum_likelihood')\n",
    "print(f'Effect: {result[\"effect\"]}')\n",
    "print(f'se: {result[\"se\"]}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
